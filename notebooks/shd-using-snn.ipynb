{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\n=============================================================================\nSPIKING HEIDELBERG DIGITS (SHD) CLASSIFICATION WITH SNNTORCH\n=============================================================================\nStep 1: Environment Setup & Reproducibility Configuration\nAuthor: AI Research Engineer\nDataset: Spiking Heidelberg Digits (SHD)\nFramework: snntorch + PyTorch + Tonic\n=============================================================================\n\"\"\"\n\n# ============================================================================\n# PART A: Install Required Libraries\n# ============================================================================\nprint(\"=\" * 80)\nprint(\"INSTALLING DEPENDENCIES\")\nprint(\"=\" * 80)\n\nimport sys\nimport subprocess\n\ndef install_package(package_name, import_name=None):\n    \"\"\"Install package if not already available.\"\"\"\n    if import_name is None:\n        import_name = package_name\n    \n    try:\n        __import__(import_name)\n        print(f\"✓ {package_name} already installed\")\n    except ImportError:\n        print(f\"Installing {package_name}...\")\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package_name])\n        print(f\"✓ {package_name} installed successfully\")\n\n# Install required packages\ninstall_package(\"snntorch\")\ninstall_package(\"tonic\")\ninstall_package(\"h5py\")\ninstall_package(\"celluloid\")  # For animation support\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"ALL DEPENDENCIES INSTALLED\")\nprint(\"=\" * 80 + \"\\n\")\n\n# ============================================================================\n# PART B: Import All Required Modules\n# ============================================================================\nprint(\"Importing libraries...\")\n\n# Standard Libraries\nimport os\nimport random\nimport warnings\nfrom pathlib import Path\nfrom typing import Tuple, Dict, List, Optional\n\n# Numerical & Data Processing\nimport numpy as np\nimport pandas as pd\nimport h5py\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.gridspec import GridSpec\nfrom IPython.display import clear_output\n\n# PyTorch & Deep Learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\n# SNNTorch - Spiking Neural Networks\nimport snntorch as snn\nfrom snntorch import surrogate\nfrom snntorch import functional as SF\nfrom snntorch import utils\n\n# Tonic - Neuromorphic Data Loading\nimport tonic\nfrom tonic import DiskCachedDataset\n\n# Training utilities\nfrom tqdm.auto import tqdm\nimport time\n\n# Suppress warnings for cleaner output\nwarnings.filterwarnings('ignore')\n\nprint(\"✓ All libraries imported successfully\\n\")\n\n# ============================================================================\n# PART C: Set Global Random Seeds for Reproducibility\n# ============================================================================\nprint(\"=\" * 80)\nprint(\"CONFIGURING REPRODUCIBILITY (seed=42)\")\nprint(\"=\" * 80)\n\nSEED = 42\n\ndef set_seed(seed: int = 42):\n    \"\"\"\n    Set random seeds for complete reproducibility across:\n    - Python's random module\n    - NumPy\n    - PyTorch (CPU and CUDA)\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n    \n    # Configure PyTorch for deterministic operations\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \n    # Set environment variable for Python hashing\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \n    print(f\"✓ Global seed set to {seed}\")\n    print(\"✓ PyTorch configured for deterministic operations\")\n    print(\"✓ CUDNN deterministic mode enabled\")\n    print(\"✓ CUDNN benchmark mode disabled\")\n\nset_seed(SEED)\n\n# ============================================================================\n# PART D: GPU Detection & Initialization\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"GPU DETECTION & INITIALIZATION\")\nprint(\"=\" * 80)\n\n# Detect available device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Device: {device}\")\n\nif torch.cuda.is_available():\n    print(f\"✓ GPU Detected: {torch.cuda.get_device_name(0)}\")\n    print(f\"✓ CUDA Version: {torch.version.cuda}\")\n    print(f\"✓ Number of GPUs: {torch.cuda.device_count()}\")\n    print(f\"✓ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    print(f\"✓ Current GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1e9:.4f} GB\")\n    print(f\"✓ Current GPU Memory Cached: {torch.cuda.memory_reserved(0) / 1e9:.4f} GB\")\nelse:\n    print(\"⚠ WARNING: GPU not available. Training will be slow on CPU.\")\n    print(\"Consider enabling GPU acceleration in Kaggle Notebook settings.\")\n\n# ============================================================================\n# PART E: Configure Visualization Settings\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"VISUALIZATION CONFIGURATION\")\nprint(\"=\" * 80)\n\n# Set plotting style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\n# Configure matplotlib for better plots\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['figure.dpi'] = 100\nplt.rcParams['font.size'] = 10\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['axes.titlesize'] = 14\nplt.rcParams['legend.fontsize'] = 10\nplt.rcParams['xtick.labelsize'] = 10\nplt.rcParams['ytick.labelsize'] = 10\n\nprint(\"✓ Visualization settings configured\")\n\n# ============================================================================\n# PART F: Define Kaggle Directory Paths\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"DIRECTORY STRUCTURE\")\nprint(\"=\" * 80)\n\n# Define paths for Kaggle environment\nBASE_DIR = Path(\"/kaggle/working\")\nDATA_DIR = Path(\"/kaggle/input\")\nOUTPUT_DIR = BASE_DIR / \"outputs\"\nMODEL_DIR = BASE_DIR / \"models\"\nCACHE_DIR = BASE_DIR / \"cache\"\n\n# Create necessary directories\nfor directory in [OUTPUT_DIR, MODEL_DIR, CACHE_DIR]:\n    directory.mkdir(parents=True, exist_ok=True)\n    print(f\"✓ Created/Verified: {directory}\")\n\n# ============================================================================\n# PART G: System Information Summary\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"SYSTEM INFORMATION SUMMARY\")\nprint(\"=\" * 80)\n\nprint(f\"Python Version: {sys.version.split()[0]}\")\nprint(f\"PyTorch Version: {torch.__version__}\")\nprint(f\"snntorch Version: {snn.__version__}\")\nprint(f\"Tonic Version: {tonic.__version__}\")\nprint(f\"NumPy Version: {np.__version__}\")\nprint(f\"Device: {device}\")\nprint(f\"Working Directory: {BASE_DIR}\")\nprint(f\"Random Seed: {SEED}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"ENVIRONMENT SETUP COMPLETE ✓\")\nprint(\"=\" * 80)\nprint(\"\\nReady to proceed to data acquisition and preprocessing.\\n\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-23T13:35:25.292868Z","iopub.execute_input":"2025-12-23T13:35:25.293169Z","iopub.status.idle":"2025-12-23T13:35:46.628367Z","shell.execute_reply.started":"2025-12-23T13:35:25.293146Z","shell.execute_reply":"2025-12-23T13:35:46.627567Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nINSTALLING DEPENDENCIES\n================================================================================\nInstalling snntorch...\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.6/125.6 kB 2.8 MB/s eta 0:00:00\n✓ snntorch installed successfully\nInstalling tonic...\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 106.2/106.2 kB 3.0 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.4/50.4 kB 2.2 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.9/131.9 kB 5.2 MB/s eta 0:00:00\n✓ tonic installed successfully\n✓ h5py already installed\nInstalling celluloid...\n✓ celluloid installed successfully\n\n================================================================================\nALL DEPENDENCIES INSTALLED\n================================================================================\n\nImporting libraries...\n✓ All libraries imported successfully\n\n================================================================================\nCONFIGURING REPRODUCIBILITY (seed=42)\n================================================================================\n✓ Global seed set to 42\n✓ PyTorch configured for deterministic operations\n✓ CUDNN deterministic mode enabled\n✓ CUDNN benchmark mode disabled\n\n================================================================================\nGPU DETECTION & INITIALIZATION\n================================================================================\nDevice: cuda\n✓ GPU Detected: Tesla T4\n✓ CUDA Version: 12.4\n✓ Number of GPUs: 2\n✓ GPU Memory: 15.83 GB\n✓ Current GPU Memory Allocated: 0.0000 GB\n✓ Current GPU Memory Cached: 0.0000 GB\n\n================================================================================\nVISUALIZATION CONFIGURATION\n================================================================================\n✓ Visualization settings configured\n\n================================================================================\nDIRECTORY STRUCTURE\n================================================================================\n✓ Created/Verified: /kaggle/working/outputs\n✓ Created/Verified: /kaggle/working/models\n✓ Created/Verified: /kaggle/working/cache\n\n================================================================================\nSYSTEM INFORMATION SUMMARY\n================================================================================\nPython Version: 3.11.13\nPyTorch Version: 2.6.0+cu124\nsnntorch Version: 0.9.4\nTonic Version: 1.6.0\nNumPy Version: 1.26.4\nDevice: cuda\nWorking Directory: /kaggle/working\nRandom Seed: 42\n\n================================================================================\nENVIRONMENT SETUP COMPLETE ✓\n================================================================================\n\nReady to proceed to data acquisition and preprocessing.\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\"\"\"\n=============================================================================\nStep 2: Data Acquisition & Preprocessing\n=============================================================================\nDownload and preprocess the Spiking Heidelberg Digits (SHD) dataset.\nThe SHD dataset contains spike trains from 700 input channels representing\nspoken digits (0-9) in German, recorded as spike events.\n=============================================================================\n\"\"\"\n\n# ============================================================================\n# PART A: Dataset Overview & Information\n# ============================================================================\nprint(\"=\" * 80)\nprint(\"SPIKING HEIDELBERG DIGITS (SHD) DATASET\")\nprint(\"=\" * 80)\n\ndataset_info = \"\"\"\nDataset: Spiking Heidelberg Digits (SHD)\nTask: Audio digit classification (0-9 in German)\nClasses: 20 classes (10 digits × 2 speakers)\nInput: Spike trains from 700 audio channels\nEncoding: Cochlear model converting audio to spike events\nTrain samples: ~8,156 samples\nTest samples: ~2,264 samples\nDuration: Variable (~1 second typical)\nFormat: HDF5 files with spike times and neuron indices\n\nKey Characteristics:\n- Neuromorphic representation of audio\n- Sparse spike events (not dense tensors)\n- Temporal information encoded in spike timing\n- Requires time-binning for SNN processing\n\"\"\"\n\nprint(dataset_info)\n\n# ============================================================================\n# PART B: Download SHD Dataset Using Tonic\n# ============================================================================\nprint(\"=\" * 80)\nprint(\"DOWNLOADING SHD DATASET\")\nprint(\"=\" * 80)\n\n# Define data directory\nSHD_DATA_DIR = BASE_DIR / \"shd_data\"\nSHD_DATA_DIR.mkdir(exist_ok=True)\n\nprint(f\"Download location: {SHD_DATA_DIR}\\n\")\n\n# Download training and test sets\nprint(\"Downloading training set...\")\ntrain_dataset_raw = tonic.datasets.SHD(\n    save_to=str(SHD_DATA_DIR),\n    train=True\n)\n\nprint(\"\\nDownloading test set...\")\ntest_dataset_raw = tonic.datasets.SHD(\n    save_to=str(SHD_DATA_DIR),\n    train=False\n)\n\nprint(\"\\n✓ Dataset downloaded successfully\")\nprint(f\"✓ Train samples: {len(train_dataset_raw)}\")\nprint(f\"✓ Test samples: {len(test_dataset_raw)}\")\n\n# ============================================================================\n# PART C: Inspect Raw Data Structure\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"INSPECTING RAW DATA STRUCTURE\")\nprint(\"=\" * 80)\n\n# Get a sample from the dataset\nsample_events, sample_label = train_dataset_raw[0]\n\nprint(f\"\\nSample Label (Class): {sample_label}\")\nprint(f\"\\nEvent Data Structure:\")\nprint(f\"Type: {type(sample_events)}\")\nprint(f\"Dtype: {sample_events.dtype}\")\nprint(f\"Shape: {sample_events.shape}\")\nprint(f\"Number of spike events: {len(sample_events)}\")\n\nprint(f\"\\nEvent Fields:\")\nfor field_name in sample_events.dtype.names:\n    print(f\"  - {field_name}: {sample_events[field_name][:5]} ...\")\n\n# Extract key statistics\nneuron_indices = sample_events['x']\nspike_times = sample_events['t']\n\nprint(f\"\\nSample Statistics:\")\nprint(f\"  Neuron indices range: {neuron_indices.min()} to {neuron_indices.max()}\")\nprint(f\"  Number of input channels: {neuron_indices.max() + 1}\")\nprint(f\"  Spike times range: {spike_times.min():.2f} to {spike_times.max():.2f} μs\")\nprint(f\"  Duration: {(spike_times.max() - spike_times.min()) / 1e6:.4f} seconds\")\nprint(f\"  Total spikes: {len(spike_times)}\")\nprint(f\"  Average firing rate: {len(spike_times) / (neuron_indices.max() + 1):.2f} spikes/neuron\")\n\n# ============================================================================\n# PART D: Analyze Dataset Statistics\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"DATASET STATISTICS ANALYSIS\")\nprint(\"=\" * 80)\n\ndef analyze_dataset_stats(dataset, name=\"Dataset\", num_samples=500):\n    \"\"\"Analyze key statistics across multiple samples.\"\"\"\n    \n    print(f\"\\nAnalyzing {name} ({num_samples} samples)...\")\n    \n    stats = {\n        'num_spikes': [],\n        'duration': [],\n        'active_neurons': [],\n        'labels': []\n    }\n    \n    # Sample random indices\n    np.random.seed(SEED)\n    indices = np.random.choice(len(dataset), min(num_samples, len(dataset)), replace=False)\n    \n    for idx in tqdm(indices, desc=f\"Analyzing {name}\"):\n        events, label = dataset[idx]\n        \n        spike_times = events['t']\n        neuron_ids = events['x']\n        \n        stats['num_spikes'].append(len(events))\n        stats['duration'].append((spike_times.max() - spike_times.min()) / 1e6)  # Convert to seconds\n        stats['active_neurons'].append(len(np.unique(neuron_ids)))\n        stats['labels'].append(label)\n    \n    return stats\n\n# Analyze both datasets\ntrain_stats = analyze_dataset_stats(train_dataset_raw, \"Train Set\", num_samples=500)\ntest_stats = analyze_dataset_stats(test_dataset_raw, \"Test Set\", num_samples=200)\n\n# Print statistics\ndef print_stats(stats, name):\n    print(f\"\\n{name} Statistics:\")\n    print(f\"  Spikes per sample: {np.mean(stats['num_spikes']):.1f} ± {np.std(stats['num_spikes']):.1f}\")\n    print(f\"  Duration (seconds): {np.mean(stats['duration']):.3f} ± {np.std(stats['duration']):.3f}\")\n    print(f\"  Active neurons: {np.mean(stats['active_neurons']):.1f} ± {np.std(stats['active_neurons']):.1f}\")\n    print(f\"  Classes: {len(np.unique(stats['labels']))} unique labels\")\n    print(f\"  Class distribution: {np.bincount(stats['labels'])}\")\n\nprint_stats(train_stats, \"Train Set\")\nprint_stats(test_stats, \"Test Set\")\n\n# ============================================================================\n# PART E: Define Time-Binning Transform\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"CONFIGURING TIME-BINNING TRANSFORM\")\nprint(\"=\" * 80)\n\n# Time-binning parameters\nNUM_TIME_BINS = 100  # Discretize time into 100 bins\nSENSOR_SIZE = (700, 1, 1)  # 700 input channels\n\nprint(f\"\"\"\nTime-Binning Configuration:\n  Input channels: {SENSOR_SIZE[0]}\n  Time bins: {NUM_TIME_BINS}\n  \nRationale:\n  - SNNs process data in discrete time steps\n  - Time-binning converts continuous spike times into discrete bins\n  - Each bin represents a simulation time step\n  - Output shape: (Time_bins, Channels) = ({NUM_TIME_BINS}, {SENSOR_SIZE[0]})\n\"\"\")\n\n# Define transform using Tonic\ntransform = tonic.transforms.Compose([\n    tonic.transforms.ToFrame(\n        sensor_size=SENSOR_SIZE,\n        n_time_bins=NUM_TIME_BINS\n    )\n])\n\nprint(\"✓ Time-binning transform configured\")\n\n# ============================================================================\n# PART F: Create Cached Datasets\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"CREATING DISK-CACHED DATASETS\")\nprint(\"=\" * 80)\n\nprint(\"\"\"\nWhy Disk Caching?\n  - Transform operations are expensive (time-binning for each sample)\n  - Caching pre-processes data once and saves to disk\n  - Dramatically speeds up training (no repeated transformations)\n  - Essential for iterative experimentation\n\"\"\")\n\n# Create cache directories\nTRAIN_CACHE = CACHE_DIR / \"shd_train_cache\"\nTEST_CACHE = CACHE_DIR / \"shd_test_cache\"\n\nprint(f\"\\nTrain cache: {TRAIN_CACHE}\")\nprint(f\"Test cache: {TEST_CACHE}\")\n\n# Create cached datasets\nprint(\"\\nCreating cached training dataset...\")\ntrain_dataset = DiskCachedDataset(\n    train_dataset_raw,\n    transform=transform,\n    cache_path=str(TRAIN_CACHE)\n)\n\nprint(\"Creating cached test dataset...\")\ntest_dataset = DiskCachedDataset(\n    test_dataset_raw,\n    transform=transform,\n    cache_path=str(TEST_CACHE)\n)\n\nprint(\"\\n✓ Cached datasets created\")\nprint(f\"✓ Train samples: {len(train_dataset)}\")\nprint(f\"✓ Test samples: {len(test_dataset)}\")\n\n# ============================================================================\n# PART G: Verify Preprocessed Data Shape\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"VERIFYING PREPROCESSED DATA\")\nprint(\"=\" * 80)\n\n# Load a preprocessed sample\nsample_frames, sample_label = train_dataset[0]\n\nprint(f\"\\nPreprocessed Sample:\")\nprint(f\"  Label: {sample_label}\")\nprint(f\"  Frames shape: {sample_frames.shape}\")\nprint(f\"  Frames dtype: {sample_frames.dtype}\")\nprint(f\"  Memory size: {sample_frames.nbytes / 1024:.2f} KB\")\n\n# Interpret shape dynamically based on actual dimensions\nprint(f\"\\nShape interpretation:\")\nif len(sample_frames.shape) == 4:\n    # Shape: (time_bins, channels, height, width)\n    print(f\"  Time bins: {sample_frames.shape[0]}\")\n    print(f\"  Channels: {sample_frames.shape[1]}\")\n    print(f\"  Height: {sample_frames.shape[2]}\")\n    print(f\"  Width: {sample_frames.shape[3]}\")\nelif len(sample_frames.shape) == 3:\n    # Shape: (time_bins, channels, 1) or (time_bins, height, width)\n    print(f\"  Time bins: {sample_frames.shape[0]}\")\n    print(f\"  Channels: {sample_frames.shape[1]}\")\n    if sample_frames.shape[2] == 1:\n        print(f\"  Extra dimension: {sample_frames.shape[2]}\")\n    else:\n        print(f\"  Spatial dims: {sample_frames.shape[2]}\")\nelif len(sample_frames.shape) == 2:\n    # Shape: (time_bins, channels)\n    print(f\"  Time bins: {sample_frames.shape[0]}\")\n    print(f\"  Channels: {sample_frames.shape[1]}\")\nelse:\n    print(f\"  Unexpected shape with {len(sample_frames.shape)} dimensions\")\n\n# Reshape if needed to (time_bins, channels) for simplicity\nif len(sample_frames.shape) > 2:\n    print(f\"\\nReshaping from {sample_frames.shape} to (time_bins, channels)...\")\n    sample_frames = sample_frames.reshape(sample_frames.shape[0], -1)\n    print(f\"  New shape: {sample_frames.shape}\")\n\n# Check spike statistics in binned data\nprint(f\"\\nBinned Data Statistics:\")\nprint(f\"  Total spikes in bins: {sample_frames.sum():.0f}\")\nprint(f\"  Non-zero bins: {(sample_frames > 0).sum():.0f}\")\nprint(f\"  Sparsity: {100 * (1 - (sample_frames > 0).sum() / sample_frames.size):.2f}%\")\nprint(f\"  Max spikes per bin: {sample_frames.max():.0f}\")\n\n# ============================================================================\n# PART H: Dataset Summary\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"DATA PREPROCESSING COMPLETE ✓\")\nprint(\"=\" * 80)\n\nsummary = f\"\"\"\nDataset Summary:\n  ✓ Train samples: {len(train_dataset)}\n  ✓ Test samples: {len(test_dataset)}\n  ✓ Input channels: {SENSOR_SIZE[0]}\n  ✓ Time bins: {NUM_TIME_BINS}\n  ✓ Number of classes: 20\n  ✓ Data format: Spike frames ({NUM_TIME_BINS}, {SENSOR_SIZE[0]}, 1, 1)\n  ✓ Caching: Enabled (disk-cached for fast loading)\n  \nReady for:\n  → Exploratory Data Analysis (EDA)\n  → DataLoader creation\n  → SNN model development\n\"\"\"\n\nprint(summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T13:40:36.279165Z","iopub.execute_input":"2025-12-23T13:40:36.280132Z","iopub.status.idle":"2025-12-23T13:40:38.986296Z","shell.execute_reply.started":"2025-12-23T13:40:36.280096Z","shell.execute_reply":"2025-12-23T13:40:38.985490Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSPIKING HEIDELBERG DIGITS (SHD) DATASET\n================================================================================\n\nDataset: Spiking Heidelberg Digits (SHD)\nTask: Audio digit classification (0-9 in German)\nClasses: 20 classes (10 digits × 2 speakers)\nInput: Spike trains from 700 audio channels\nEncoding: Cochlear model converting audio to spike events\nTrain samples: ~8,156 samples\nTest samples: ~2,264 samples\nDuration: Variable (~1 second typical)\nFormat: HDF5 files with spike times and neuron indices\n\nKey Characteristics:\n- Neuromorphic representation of audio\n- Sparse spike events (not dense tensors)\n- Temporal information encoded in spike timing\n- Requires time-binning for SNN processing\n\n================================================================================\nDOWNLOADING SHD DATASET\n================================================================================\nDownload location: /kaggle/working/shd_data\n\nDownloading training set...\n\nDownloading test set...\n\n✓ Dataset downloaded successfully\n✓ Train samples: 8156\n✓ Test samples: 2264\n\n================================================================================\nINSPECTING RAW DATA STRUCTURE\n================================================================================\n\nSample Label (Class): 11\n\nEvent Data Structure:\nType: <class 'numpy.ndarray'>\nDtype: [('t', '<i8'), ('x', '<i8'), ('p', '<i8')]\nShape: (4278,)\nNumber of spike events: 4278\n\nEvent Fields:\n  - t: [   0 1832 2166 4123 5542] ...\n  - x: [384 680 465 189 498] ...\n  - p: [1 1 1 1 1] ...\n\nSample Statistics:\n  Neuron indices range: 1 to 696\n  Number of input channels: 697\n  Spike times range: 0.00 to 700683.00 μs\n  Duration: 0.7007 seconds\n  Total spikes: 4278\n  Average firing rate: 6.14 spikes/neuron\n\n================================================================================\nDATASET STATISTICS ANALYSIS\n================================================================================\n\nAnalyzing Train Set (500 samples)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Analyzing Train Set:   0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b17edabd92e7426f8e69bfc4237ed09b"}},"metadata":{}},{"name":"stdout","text":"\nAnalyzing Test Set (200 samples)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Analyzing Test Set:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ddbca5d745f4a9c8fff117617a56192"}},"metadata":{}},{"name":"stdout","text":"\nTrain Set Statistics:\n  Spikes per sample: 7934.4 ± 2423.0\n  Duration (seconds): 0.711 ± 0.134\n  Active neurons: 564.9 ± 41.7\n  Classes: 20 unique labels\n  Class distribution: [27 29 25 32 29 20 23 27 29 22 22 26 18 24 19 23 29 29 27 20]\n\nTest Set Statistics:\n  Spikes per sample: 8313.1 ± 2291.3\n  Duration (seconds): 0.718 ± 0.113\n  Active neurons: 571.4 ± 39.7\n  Classes: 20 unique labels\n  Class distribution: [ 9  9 10  5 11  6  8  8  6 13 14 13  9  8 10 12 14 15 12  8]\n\n================================================================================\nCONFIGURING TIME-BINNING TRANSFORM\n================================================================================\n\nTime-Binning Configuration:\n  Input channels: 700\n  Time bins: 100\n  \nRationale:\n  - SNNs process data in discrete time steps\n  - Time-binning converts continuous spike times into discrete bins\n  - Each bin represents a simulation time step\n  - Output shape: (Time_bins, Channels) = (100, 700)\n\n✓ Time-binning transform configured\n\n================================================================================\nCREATING DISK-CACHED DATASETS\n================================================================================\n\nWhy Disk Caching?\n  - Transform operations are expensive (time-binning for each sample)\n  - Caching pre-processes data once and saves to disk\n  - Dramatically speeds up training (no repeated transformations)\n  - Essential for iterative experimentation\n\n\nTrain cache: /kaggle/working/cache/shd_train_cache\nTest cache: /kaggle/working/cache/shd_test_cache\n\nCreating cached training dataset...\nCreating cached test dataset...\n\n✓ Cached datasets created\n✓ Train samples: 8156\n✓ Test samples: 2264\n\n================================================================================\nVERIFYING PREPROCESSED DATA\n================================================================================\n\nPreprocessed Sample:\n  Label: 11\n  Frames shape: (100, 1, 700)\n  Frames dtype: int16\n  Memory size: 136.72 KB\n\nShape interpretation:\n  Time bins: 100\n  Channels: 1\n  Spatial dims: 700\n\nReshaping from (100, 1, 700) to (time_bins, channels)...\n  New shape: (100, 700)\n\nBinned Data Statistics:\n  Total spikes in bins: 4277\n  Non-zero bins: 3854\n  Sparsity: 94.49%\n  Max spikes per bin: 3\n\n================================================================================\nDATA PREPROCESSING COMPLETE ✓\n================================================================================\n\nDataset Summary:\n  ✓ Train samples: 8156\n  ✓ Test samples: 2264\n  ✓ Input channels: 700\n  ✓ Time bins: 100\n  ✓ Number of classes: 20\n  ✓ Data format: Spike frames (100, 700, 1, 1)\n  ✓ Caching: Enabled (disk-cached for fast loading)\n  \nReady for:\n  → Exploratory Data Analysis (EDA)\n  → DataLoader creation\n  → SNN model development\n\n","output_type":"stream"}],"execution_count":3}]}